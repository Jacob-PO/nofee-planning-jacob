"""
ë‹¹ê·¼ë§ˆì¼“ íœ´ëŒ€í° ë§¤ì¥ í¬ë¡¤ëŸ¬ V2 (ì„¸ë¶„í™” ë²„ì „)
- êµ¬ ë‹¨ìœ„ + ì—­ ë‹¨ìœ„ + ë™ ë‹¨ìœ„ ê²€ìƒ‰
- ë” ë§ì€ 010 ì „í™”ë²ˆí˜¸ ìˆ˜ì§‘
"""

import time
import re
import random
from datetime import datetime
from pathlib import Path
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException

class DaangnStoreCrawlerV2:
    """ë‹¹ê·¼ë§ˆì¼“ íœ´ëŒ€í° ë§¤ì¥ í¬ë¡¤ëŸ¬ V2 (ì„¸ë¶„í™”)"""

    def __init__(self, google_api_key_path=None, headless=False):
        self.base_path = Path(__file__).parent
        self.output_path = self.base_path / 'output'
        self.output_path.mkdir(exist_ok=True)

        if google_api_key_path is None:
            self.google_api_key_path = Path('/Users/jacob/Desktop/dev/config/google_api_key.json')
        else:
            self.google_api_key_path = Path(google_api_key_path)

        # Chrome ì˜µì…˜ ì„¤ì •
        self.chrome_options = Options()
        if headless:
            self.chrome_options.add_argument('--headless')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')

        # User-Agent ëœë¤í™”
        user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        ]
        self.chrome_options.add_argument(f'user-agent={random.choice(user_agents)}')
        self.chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        self.chrome_options.add_argument('--lang=ko-KR')

        self.driver = None

        # ì„¸ë¶„í™”ëœ ì§€ì—­ (ì—­ ë‹¨ìœ„ + ë™ ë‹¨ìœ„)
        self.regions = [
            # ì„œìš¸ ê°•ë‚¨êµ¬ ì„¸ë¶„í™”
            'ê°•ë‚¨ì—­', 'ì—­ì‚¼ì—­', 'ì„ ë¦‰ì—­', 'ì‚¼ì„±ì—­', 'ì‹ ì‚¬ì—­', 'ì••êµ¬ì •ì—­', 'ì²­ë‹´ì—­',
            'ëŒ€ì¹˜ë™', 'ì—­ì‚¼ë™', 'ì‚¼ì„±ë™', 'ì²­ë‹´ë™', 'ì‹ ì‚¬ë™', 'ì••êµ¬ì •ë™', 'ë…¼í˜„ë™',

            # ì„œìš¸ ê°•ë™êµ¬ ì„¸ë¶„í™”
            'ì²œí˜¸ì—­', 'ê°•ë™ì—­', 'ë‘”ì´Œë™ì—­', 'ê³ ë•ì—­', 'ìƒì¼ë™ì—­',
            'ì²œí˜¸ë™', 'ì„±ë‚´ë™', 'ë‘”ì´Œë™', 'ì•”ì‚¬ë™', 'ê°•ì¼ë™', 'ìƒì¼ë™',

            # ì„œìš¸ ì†¡íŒŒêµ¬ ì„¸ë¶„í™”
            'ì ì‹¤ì—­', 'ì„ì´Œì—­', 'ì†¡íŒŒì—­', 'ê°€ë½ì‹œì¥ì—­', 'ë¬¸ì •ì—­', 'ì¥ì§€ì—­',
            'ì ì‹¤ë™', 'ì‹ ì²œë™', 'ì†¡íŒŒë™', 'ê°€ë½ë™', 'ë¬¸ì •ë™', 'ì¥ì§€ë™',

            # ì„œìš¸ ì„œì´ˆêµ¬ ì„¸ë¶„í™”
            'ê°•ë‚¨ì—­', 'êµëŒ€ì—­', 'ì„œì´ˆì—­', 'ë°©ë°°ì—­', 'ì‚¬ë‹¹ì—­', 'ë‚¨ë¶€í„°ë¯¸ë„ì—­',
            'ì„œì´ˆë™', 'ë°©ë°°ë™', 'ì ì›ë™', 'ë°˜í¬ë™', 'ì–‘ì¬ë™',

            # ì„œìš¸ ì˜ë“±í¬êµ¬ ì„¸ë¶„í™”
            'ì˜ë“±í¬ì—­', 'ì‹ ê¸¸ì—­', 'ì—¬ì˜ë„ì—­', 'ë‹¹ì‚°ì—­', 'ë¬¸ë˜ì—­',
            'ì˜ë“±í¬ë™', 'ì‹ ê¸¸ë™', 'ì—¬ì˜ë„ë™', 'ë‹¹ì‚°ë™', 'ë¬¸ë˜ë™',

            # ì„œìš¸ ë§ˆí¬êµ¬ ì„¸ë¶„í™”
            'í™ëŒ€ì…êµ¬ì—­', 'ì‹ ì´Œì—­', 'í•©ì •ì—­', 'ìƒìˆ˜ì—­', 'ë§ì›ì—­',
            'í™ëŒ€', 'ì‹ ì´Œ', 'í•©ì •', 'ë§ì›ë™', 'ìƒìˆ˜ë™', 'ì—°ë‚¨ë™',

            # ì„œìš¸ êµ¬ë¡œêµ¬ ì„¸ë¶„í™”
            'êµ¬ë¡œë””ì§€í„¸ë‹¨ì§€ì—­', 'ì‹ ë„ë¦¼ì—­', 'êµ¬ë¡œì—­', 'ê°€ì‚°ë””ì§€í„¸ë‹¨ì§€ì—­',
            'êµ¬ë¡œë™', 'ì‹ ë„ë¦¼ë™', 'ê°€ë¦¬ë´‰ë™', 'ê°€ì‚°ë™',

            # ê²½ê¸° ì„±ë‚¨ ì„¸ë¶„í™”
            'ë¶„ë‹¹', 'íŒêµ', 'ì•¼íƒ‘', 'ì„œí˜„', 'ìˆ˜ë‚´', 'ì •ì',
            'ë¶„ë‹¹êµ¬', 'ìˆ˜ì •êµ¬', 'ì¤‘ì›êµ¬', 'íŒêµì—­', 'ì•¼íƒ‘ì—­', 'ì„œí˜„ì—­',

            # ê²½ê¸° ìˆ˜ì› ì„¸ë¶„í™”
            'ìˆ˜ì›ì—­', 'ìˆ˜ì›ì‹œì²­ì—­', 'ì˜í†µì—­', 'ê´‘êµì—­', 'ë§¤íƒ„ì—­',
            'íŒ”ë‹¬êµ¬', 'ì˜í†µêµ¬', 'ê¶Œì„ êµ¬', 'ì¥ì•ˆêµ¬',

            # ì¸ì²œ ì„¸ë¶„í™”
            'ë¶€í‰ì—­', 'êµ¬ì›”ë™', 'ì£¼ì•ˆì—­', 'ë¶€í‰', 'ê³„ì–‘',
            'ë¶€í‰êµ¬', 'ê³„ì–‘êµ¬', 'ë‚¨ë™êµ¬', 'ì—°ìˆ˜êµ¬',
        ]

        # í‚¤ì›Œë“œ (ê¸°ì¡´ ìœ ì§€)
        self.keywords = [
            'íœ´ëŒ€í°ë§¤ì¥', 'íœ´ëŒ€í°ì„±ì§€', 'ìŠ¤ë§ˆíŠ¸í°ë§¤ì¥', 'í°ë§¤ì¥',
            'íœ´ëŒ€í°ê°€ê²Œ', 'í•¸ë“œí°ê°€ê²Œ', 'ë™ë„¤íœ´ëŒ€í°ë§¤ì¥',
            'íœ´ëŒ€í°íŒë§¤', 'íœ´ëŒ€í°ëŒ€ë¦¬ì ', 'í•¸ë“œí°ë§¤ì¥', 'í•¸ë“œí°íŒë§¤',
            'ìŠ¤ë§ˆíŠ¸í°íŒë§¤', 'íœ´ëŒ€í°ê°œí†µ', 'ê¸°ê¸°ë³€ê²½', 'ë²ˆí˜¸ì´ë™',
            'ì•„ì´í°', 'ê°¤ëŸ­ì‹œ', 'ì•„ì´í°ë§¤ì¥', 'ê°¤ëŸ­ì‹œë§¤ì¥',
            'ì•„ì´í°íŒë§¤', 'ê°¤ëŸ­ì‹œíŒë§¤',
            'íœ´ëŒ€í°ë§¤ì¥ì¶”ì²œ', 'ë¯¿ì„ë§Œí•œíœ´ëŒ€í°ë§¤ì¥', 'ì•ˆì „í•œê°œí†µ',
            'íœ´ëŒ€í°ì„±ì§€í›„ê¸°', 'íœ´ëŒ€í°ë§¤ì¥í›„ê¸°',
        ]

        self.collected_stores = set()

    def init_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”"""
        try:
            self.driver = webdriver.Chrome(options=self.chrome_options)
            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                '''
            })
            print("âœ… Chrome ë¸Œë¼ìš°ì € ì‹œì‘ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False

    def close_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            try:
                self.driver.quit()
                self.driver = None
            except:
                pass

    def extract_010_phones(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ 010 ì „í™”ë²ˆí˜¸ë§Œ ì¶”ì¶œ"""
        if not text:
            return []

        pattern = r'010[-\s]?\d{3,4}[-\s]?\d{4}'
        phones = re.findall(pattern, text)

        normalized = []
        for phone in phones:
            digits = re.sub(r'[-\s]', '', phone)
            if len(digits) == 11:
                formatted = f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
                normalized.append(formatted)
            elif len(digits) == 10:
                formatted = f"{digits[:3]}-{digits[3:6]}-{digits[6:]}"
                normalized.append(formatted)

        return list(set(normalized))

    def search_daangn(self, region, keyword):
        """ë‹¹ê·¼ë§ˆì¼“ ê²€ìƒ‰"""
        query = f"{region} {keyword}"
        search_url = f"https://www.google.com/search?q=ë‹¹ê·¼ë§ˆì¼“+{query}"

        try:
            self.driver.get(search_url)
            time.sleep(random.uniform(3, 5))

            # êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ daangn.com ë§í¬ ìˆ˜ì§‘
            links = self.driver.find_elements(By.TAG_NAME, 'a')
            daangn_links = []

            for link in links:
                href = link.get_attribute('href')
                if href and 'daangn.com/kr/local-profile/' in href:
                    daangn_links.append(href)

            # ì¤‘ë³µ ì œê±°
            daangn_links = list(set(daangn_links))
            print(f"    ğŸ“Œ {len(daangn_links)}ê°œ daangn.com ë§í¬ ë°œê²¬")

            return daangn_links[:20]  # ìƒìœ„ 20ê°œë§Œ

        except Exception as e:
            print(f"    âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    def get_store_detail(self, link):
        """ë§¤ì¥ ìƒì„¸ ì •ë³´"""
        try:
            self.driver.get(link)
            time.sleep(random.uniform(2, 3))

            # ë§¤ì¥ëª…
            try:
                name_elem = self.driver.find_element(By.CSS_SELECTOR, "h1, h2, [class*='name'], [class*='title']")
                store_name = name_elem.text.strip()
            except:
                store_name = "ì•Œ ìˆ˜ ì—†ìŒ"

            # ì „í™”ë²ˆí˜¸
            page_text = self.driver.find_element(By.TAG_NAME, 'body').text
            phones = self.extract_010_phones(page_text)

            if phones and store_name != "ì•Œ ìˆ˜ ì—†ìŒ":
                return {
                    'name': store_name,
                    'phones': phones,
                    'link': link
                }

            return None

        except Exception as e:
            return None

    def save_intermediate_results(self, results, search_count):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        if not results:
            return

        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = self.output_path / f'daangn_v2_intermediate_{search_count}searches_{timestamp}.csv'

            df = pd.DataFrame(results)
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"    ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {len(results)}ê°œ ë§¤ì¥ â†’ {filename.name}")
        except Exception as e:
            print(f"    âš ï¸  ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    def crawl(self, max_searches=3000, save_interval=50):
        """í¬ë¡¤ë§ ì‹¤í–‰"""
        print("=" * 80)
        print("ğŸ¥• ë‹¹ê·¼ë§ˆì¼“ í¬ë¡¤ëŸ¬ V2 (ì„¸ë¶„í™” ë²„ì „)")
        print("=" * 80)
        print(f"ğŸ“ ì´ ì§€ì—­ ìˆ˜: {len(self.regions)}ê°œ (ì—­/ë™ ë‹¨ìœ„)")
        print(f"ğŸ”‘ ì´ í‚¤ì›Œë“œ ìˆ˜: {len(self.keywords)}ê°œ")
        print(f"ğŸ“Š ìµœëŒ€ ê²€ìƒ‰ ì¡°í•©: {len(self.regions) * len(self.keywords)}ê°œ")
        print("=" * 80)

        all_results = []
        search_count = 0
        max_retries = 3
        retry_count = 0

        for region in self.regions:
            for keyword in self.keywords:
                search_count += 1

                if search_count > max_searches:
                    break

                print(f"\n[{search_count}/{max_searches}] ğŸ” {region} {keyword}")

                while retry_count < max_retries:
                    try:
                        if self.driver is None:
                            print("    ğŸ”„ ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™” ì¤‘...")
                            if not self.init_driver():
                                retry_count += 1
                                time.sleep(5)
                                continue
                            retry_count = 0

                        # ë‹¹ê·¼ë§ˆì¼“ ê²€ìƒ‰
                        links = self.search_daangn(region, keyword)

                        # ê° ë§í¬ì—ì„œ 010 ì „í™”ë²ˆí˜¸ ìˆ˜ì§‘
                        for link in links:
                            detail = self.get_store_detail(link)
                            if detail:
                                for phone in detail['phones']:
                                    store_key = f"{detail['name']}_{phone}"
                                    if store_key not in self.collected_stores:
                                        self.collected_stores.add(store_key)
                                        all_results.append({
                                            'ì§€ì—­ëª…': region,
                                            'ë§¤ì¥ëª…': detail['name'],
                                            'ì „í™”ë²ˆí˜¸': phone,
                                            'ë§í¬': detail['link']
                                        })
                                        print(f"      ğŸ’¾ ì €ì¥: {detail['name']} ({phone})")

                            time.sleep(random.uniform(1, 2))

                        # ì¤‘ê°„ ì €ì¥
                        if search_count % save_interval == 0:
                            print(f"\nğŸ“¦ ì¤‘ê°„ ì €ì¥ ì‹œì  ({search_count}ë²ˆ ê²€ìƒ‰ ì™„ë£Œ)")
                            self.save_intermediate_results(all_results, search_count)

                        # ê²€ìƒ‰ ê°„ê²© (Google ë´‡ íƒì§€ íšŒí”¼)
                        wait_time = random.uniform(10, 15)
                        print(f"    â³ {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                        time.sleep(wait_time)

                        break

                    except Exception as e:
                        print(f"    âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        self.close_driver()
                        self.driver = None
                        retry_count += 1
                        if retry_count >= max_retries:
                            print(f"    âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                            break
                        time.sleep(5)

                retry_count = 0

            if search_count > max_searches:
                break

        print("\n" + "=" * 80)
        print("âœ… ìµœì¢… í¬ë¡¤ë§ ì™„ë£Œ")
        print("=" * 80)
        print(f"ğŸ“Š ì´ ê²€ìƒ‰ íšŸìˆ˜: {search_count}íšŒ")
        print(f"ğŸ’¾ ìˆ˜ì§‘ëœ ë§¤ì¥: {len(all_results)}ê°œ")

        if all_results:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            df = pd.DataFrame(all_results)
            final_filename = self.output_path / f'daangn_v2_stores_{timestamp}.csv'
            df.to_csv(final_filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥: {final_filename}")

            self.save_intermediate_results(all_results, search_count)

        self.close_driver()
        return all_results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¥• ë‹¹ê·¼ë§ˆì¼“ V2 í¬ë¡¤ë§ ì‹œì‘ (ì—­/ë™ ë‹¨ìœ„ ì„¸ë¶„í™”)...")

    crawler = DaangnStoreCrawlerV2(headless=True)
    results = crawler.crawl(max_searches=3000, save_interval=50)

    print(f"\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(results)}ê°œ ë§¤ì¥ ìˆ˜ì§‘")

if __name__ == "__main__":
    main()
