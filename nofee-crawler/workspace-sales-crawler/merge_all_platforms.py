"""
ë³µìˆ˜ í”Œë«í¼ ë°ì´í„° í†µí•© ìŠ¤í¬ë¦½íŠ¸
- ë‹¹ê·¼ë§ˆì¼“, ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤, ì¹´ì¹´ì˜¤ë§µ, êµ¬ê¸€ ë§ˆì´ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° í†µí•©
- ì¤‘ë³µ ì œê±° (ë§¤ì¥ëª… + ì „í™”ë²ˆí˜¸ ê¸°ì¤€)
- ìµœì¢… í†µí•© CSV ìƒì„± ë° êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
import gspread
from google.oauth2.service_account import Credentials

class PlatformMerger:
    """í”Œë«í¼ ë°ì´í„° í†µí•©ê¸°"""

    def __init__(self, google_api_key_path=None):
        self.base_path = Path(__file__).parent
        self.output_path = self.base_path / 'merged_output'
        self.output_path.mkdir(exist_ok=True)

        if google_api_key_path is None:
            self.google_api_key_path = Path('/Users/jacob/Desktop/dev/config/google_api_key.json')
        else:
            self.google_api_key_path = Path(google_api_key_path)

        # ê° í”Œë«í¼ í¬ë¡¤ëŸ¬ì˜ output í´ë” ê²½ë¡œ
        self.platform_paths = {
            'daangn': self.base_path / 'google-phone-store-crawler' / 'output',
            'naver': self.base_path / 'naver-place-crawler' / 'output',
            'kakao': self.base_path / 'kakao-map-crawler' / 'output',
            'google': self.base_path / 'google-mybusiness-crawler' / 'output',
        }

    def load_platform_data(self, platform_name, file_pattern):
        """íŠ¹ì • í”Œë«í¼ì˜ ìµœì‹  ë°ì´í„° ë¡œë“œ"""
        platform_path = self.platform_paths.get(platform_name)

        if not platform_path or not platform_path.exists():
            print(f"âš ï¸  {platform_name} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {platform_path}")
            return pd.DataFrame()

        # ìµœì‹  CSV íŒŒì¼ ì°¾ê¸°
        csv_files = list(platform_path.glob(file_pattern))

        if not csv_files:
            print(f"âš ï¸  {platform_name}ì—ì„œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()

        # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
        latest_file = max(csv_files, key=lambda x: x.stat().st_mtime)
        print(f"ğŸ“‚ {platform_name}: {latest_file.name} ë¡œë“œ ì¤‘...")

        try:
            df = pd.read_csv(latest_file, encoding='utf-8-sig')
            print(f"   âœ… {len(df)}ê°œ í–‰ ë¡œë“œ ì™„ë£Œ")
            return df
        except Exception as e:
            print(f"   âŒ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame()

    def standardize_columns(self, df, platform_name):
        """ì»¬ëŸ¼ëª… í‘œì¤€í™”"""
        # ëª¨ë“  í”Œë«í¼ì„ ë™ì¼í•œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ í†µì¼
        column_mapping = {
            'ì§€ì—­ëª…': 'ì§€ì—­ëª…',
            'ë§¤ì¥ëª…': 'ë§¤ì¥ëª…',
            'ì „í™”ë²ˆí˜¸': 'ì „í™”ë²ˆí˜¸',
            'ë§í¬': 'ë§í¬',
        }

        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
        if 'ì§€ì—­ëª…_ë§¤ì¥ëª…' in df.columns:
            df = df.drop(columns=['ì§€ì—­ëª…_ë§¤ì¥ëª…'])

        # í”Œë«í¼ ì¶œì²˜ ì»¬ëŸ¼ ì¶”ê°€
        df['í”Œë«í¼'] = platform_name

        return df

    def remove_duplicates(self, merged_df):
        """ì¤‘ë³µ ì œê±° (ë§¤ì¥ëª… + ì „í™”ë²ˆí˜¸ ê¸°ì¤€)"""
        print("\nğŸ” ì¤‘ë³µ ì œê±° ì¤‘...")

        before_count = len(merged_df)

        # ë§¤ì¥ëª… + ì „í™”ë²ˆí˜¸ ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        merged_df['unique_key'] = merged_df['ë§¤ì¥ëª…'] + '_' + merged_df['ì „í™”ë²ˆí˜¸']
        merged_df = merged_df.drop_duplicates(subset=['unique_key'], keep='first')
        merged_df = merged_df.drop(columns=['unique_key'])

        after_count = len(merged_df)
        removed_count = before_count - after_count

        print(f"   ì œê±° ì „: {before_count}ê°œ")
        print(f"   ì œê±° í›„: {after_count}ê°œ")
        print(f"   ì œê±°ë¨: {removed_count}ê°œ ì¤‘ë³µ")

        return merged_df

    def merge_all_platforms(self):
        """ëª¨ë“  í”Œë«í¼ ë°ì´í„° í†µí•©"""
        print("=" * 80)
        print("ğŸ“Š ë³µìˆ˜ í”Œë«í¼ ë°ì´í„° í†µí•© ì‹œì‘")
        print("=" * 80)

        all_dataframes = []

        # 1. ë‹¹ê·¼ë§ˆì¼“ ë°ì´í„° ë¡œë“œ
        daangn_df = self.load_platform_data('daangn', 'daangn_stores_*.csv')
        if not daangn_df.empty:
            daangn_df = self.standardize_columns(daangn_df, 'ë‹¹ê·¼ë§ˆì¼“')
            all_dataframes.append(daangn_df)

        # 2. ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë°ì´í„° ë¡œë“œ
        naver_df = self.load_platform_data('naver', 'naver_stores_*.csv')
        if not naver_df.empty:
            naver_df = self.standardize_columns(naver_df, 'ë„¤ì´ë²„í”Œë ˆì´ìŠ¤')
            all_dataframes.append(naver_df)

        # 3. ì¹´ì¹´ì˜¤ë§µ ë°ì´í„° ë¡œë“œ
        kakao_df = self.load_platform_data('kakao', 'kakao_stores_*.csv')
        if not kakao_df.empty:
            kakao_df = self.standardize_columns(kakao_df, 'ì¹´ì¹´ì˜¤ë§µ')
            all_dataframes.append(kakao_df)

        # 4. êµ¬ê¸€ ë§ˆì´ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ë¡œë“œ
        google_df = self.load_platform_data('google', 'google_stores_*.csv')
        if not google_df.empty:
            google_df = self.standardize_columns(google_df, 'êµ¬ê¸€ë§ˆì´ë¹„ì¦ˆë‹ˆìŠ¤')
            all_dataframes.append(google_df)

        if not all_dataframes:
            print("\nâŒ í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return None

        # ë°ì´í„° í†µí•©
        print("\nğŸ“¦ ë°ì´í„° í†µí•© ì¤‘...")
        merged_df = pd.concat(all_dataframes, ignore_index=True)
        print(f"   ì´ {len(merged_df)}ê°œ í–‰ (ì¤‘ë³µ í¬í•¨)")

        # ì¤‘ë³µ ì œê±°
        merged_df = self.remove_duplicates(merged_df)

        # í”Œë«í¼ë³„ í†µê³„
        print("\nğŸ“ˆ í”Œë«í¼ë³„ í†µê³„:")
        platform_stats = merged_df['í”Œë«í¼'].value_counts()
        for platform, count in platform_stats.items():
            print(f"   {platform}: {count}ê°œ")

        return merged_df

    def save_merged_data(self, merged_df):
        """í†µí•© ë°ì´í„° ì €ì¥"""
        if merged_df is None or merged_df.empty:
            print("\nâŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = self.output_path / f'merged_all_platforms_{timestamp}.csv'

        # CSV ì €ì¥
        merged_df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ í†µí•© CSV ì €ì¥ ì™„ë£Œ: {filename}")

        return filename

    def upload_to_google_sheets(self, merged_df, worksheet_name='merged'):
        """êµ¬ê¸€ ì‹œíŠ¸ì— ì—…ë¡œë“œ"""
        if merged_df is None or merged_df.empty:
            print("\nâŒ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        try:
            print(f"\nğŸ“¤ êµ¬ê¸€ ì‹œíŠ¸ '{worksheet_name}'ì— ì—…ë¡œë“œ ì¤‘...")

            # Google Sheets API ì¸ì¦
            scope = [
                'https://spreadsheets.google.com/feeds',
                'https://www.googleapis.com/auth/drive'
            ]
            creds = Credentials.from_service_account_file(
                str(self.google_api_key_path),
                scopes=scope
            )
            client = gspread.authorize(creds)

            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
            spreadsheet_url = 'https://docs.google.com/spreadsheets/d/1_kRQWg7yvwGP8uXGkrXLzL82bNLLVN4S-VYkvI-cJMw/edit?gid=0#gid=0'
            spreadsheet = client.open_by_url(spreadsheet_url)

            # ì›Œí¬ì‹œíŠ¸ ì„ íƒ ë˜ëŠ” ìƒì„±
            try:
                worksheet = spreadsheet.worksheet(worksheet_name)
                worksheet.clear()  # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            except:
                worksheet = spreadsheet.add_worksheet(
                    title=worksheet_name,
                    rows=len(merged_df) + 1,
                    cols=len(merged_df.columns)
                )

            # NaN ê°’ ì²˜ë¦¬
            merged_df = merged_df.fillna('')

            # í—¤ë” + ë°ì´í„° ì¤€ë¹„
            headers = merged_df.columns.tolist()
            data_rows = merged_df.astype(str).values.tolist()
            all_data = [headers] + data_rows

            # ì—…ë¡œë“œ
            worksheet.update(values=all_data, range_name='A1')

            print(f"   âœ… {len(merged_df)}ê°œ í–‰ ì—…ë¡œë“œ ì™„ë£Œ!")
            print(f"   ğŸ”— {spreadsheet_url}")

            return True

        except Exception as e:
            print(f"   âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë³µìˆ˜ í”Œë«í¼ ë°ì´í„° í†µí•© ì‹œì‘...\n")

    merger = PlatformMerger()

    # 1. ëª¨ë“  í”Œë«í¼ ë°ì´í„° í†µí•©
    merged_df = merger.merge_all_platforms()

    if merged_df is not None and not merged_df.empty:
        # 2. CSV íŒŒì¼ë¡œ ì €ì¥
        csv_file = merger.save_merged_data(merged_df)

        # 3. êµ¬ê¸€ ì‹œíŠ¸ì— ì—…ë¡œë“œ
        merger.upload_to_google_sheets(merged_df, worksheet_name='merged')

        print("\n" + "=" * 80)
        print(f"ğŸ‰ í†µí•© ì™„ë£Œ! ìµœì¢… {len(merged_df)}ê°œ ë§¤ì¥ ìˆ˜ì§‘")
        print("=" * 80)
    else:
        print("\nâŒ í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main()
