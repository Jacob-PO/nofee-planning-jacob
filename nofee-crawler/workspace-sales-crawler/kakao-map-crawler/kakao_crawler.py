"""
ì¹´ì¹´ì˜¤ë§µ íœ´ëŒ€í° ë§¤ì¥ í¬ë¡¤ëŸ¬ (Selenium ë²„ì „)
- Chrome ë¸Œë¼ìš°ì €ë¥¼ ì§ì ‘ ì œì–´
- ì¹´ì¹´ì˜¤ë§µì—ì„œ ë§¤ì¥ ê²€ìƒ‰
- 010 ì „í™”ë²ˆí˜¸ë§Œ í•„í„°ë§í•˜ì—¬ ìˆ˜ì§‘
"""

import time
import re
import random
from datetime import datetime
from pathlib import Path
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException

class KakaoMapCrawler:
    """ì¹´ì¹´ì˜¤ë§µ íœ´ëŒ€í° ë§¤ì¥ í¬ë¡¤ëŸ¬"""

    def __init__(self, google_api_key_path=None, headless=False):
        self.base_path = Path(__file__).parent
        self.output_path = self.base_path / 'output'
        self.output_path.mkdir(exist_ok=True)

        if google_api_key_path is None:
            self.google_api_key_path = Path('/Users/jacob/Desktop/dev/config/google_api_key.json')
        else:
            self.google_api_key_path = Path(google_api_key_path)

        # Chrome ì˜µì…˜ ì„¤ì •
        self.chrome_options = Options()
        if headless:
            self.chrome_options.add_argument('--headless')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')

        # User-Agent ëœë¤í™”
        user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        ]
        self.chrome_options.add_argument(f'user-agent={random.choice(user_agents)}')
        self.chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        self.chrome_options.add_argument('--window-size=1920,1080')

        self.driver = None

        # ì„œìš¸/ìˆ˜ë„ê¶Œ ì§€ì—­ (79ê°œ)
        self.regions = [
            # ì„œìš¸ 25ê°œ êµ¬
            'ì„œìš¸ ê°•ë‚¨êµ¬', 'ì„œìš¸ ê°•ë™êµ¬', 'ì„œìš¸ ê°•ë¶êµ¬', 'ì„œìš¸ ê°•ì„œêµ¬',
            'ì„œìš¸ ê´€ì•…êµ¬', 'ì„œìš¸ ê´‘ì§„êµ¬', 'ì„œìš¸ êµ¬ë¡œêµ¬', 'ì„œìš¸ ê¸ˆì²œêµ¬',
            'ì„œìš¸ ë…¸ì›êµ¬', 'ì„œìš¸ ë„ë´‰êµ¬', 'ì„œìš¸ ë™ëŒ€ë¬¸êµ¬', 'ì„œìš¸ ë™ì‘êµ¬',
            'ì„œìš¸ ë§ˆí¬êµ¬', 'ì„œìš¸ ì„œëŒ€ë¬¸êµ¬', 'ì„œìš¸ ì„œì´ˆêµ¬', 'ì„œìš¸ ì„±ë™êµ¬',
            'ì„œìš¸ ì„±ë¶êµ¬', 'ì„œìš¸ ì†¡íŒŒêµ¬', 'ì„œìš¸ ì–‘ì²œêµ¬', 'ì„œìš¸ ì˜ë“±í¬êµ¬',
            'ì„œìš¸ ìš©ì‚°êµ¬', 'ì„œìš¸ ì€í‰êµ¬', 'ì„œìš¸ ì¢…ë¡œêµ¬', 'ì„œìš¸ ì¤‘êµ¬', 'ì„œìš¸ ì¤‘ë‘êµ¬',

            # ê²½ê¸° + ì¸ì²œ
            'ê²½ê¸° ì„±ë‚¨', 'ê²½ê¸° ìˆ˜ì›', 'ê²½ê¸° ì•ˆì–‘', 'ê²½ê¸° ì•ˆì‚°', 'ê²½ê¸° ìš©ì¸',
            'ê²½ê¸° ê´‘ëª…', 'ê²½ê¸° ê³¼ì²œ', 'ê²½ê¸° ì˜ì™•', 'ê²½ê¸° êµ°í¬', 'ê²½ê¸° ì‹œí¥',
            'ê²½ê¸° ë¶€ì²œ', 'ê²½ê¸° ê´‘ì£¼', 'ê²½ê¸° í•˜ë‚¨', 'ê²½ê¸° í™”ì„±', 'ê²½ê¸° ì˜¤ì‚°',
            'ê²½ê¸° ê³ ì–‘', 'ê²½ê¸° íŒŒì£¼', 'ê²½ê¸° ì˜ì •ë¶€', 'ê²½ê¸° ì–‘ì£¼', 'ê²½ê¸° ë™ë‘ì²œ',
            'ê²½ê¸° ë‚¨ì–‘ì£¼', 'ê²½ê¸° êµ¬ë¦¬', 'ê²½ê¸° í¬ì²œ', 'ê²½ê¸° ì—°ì²œ', 'ê²½ê¸° ê°€í‰',
            'ê²½ê¸° ì´ì²œ', 'ê²½ê¸° ì—¬ì£¼', 'ê²½ê¸° ì–‘í‰', 'ê²½ê¸° ê¹€í¬',
            'ì¸ì²œ ì¤‘êµ¬', 'ì¸ì²œ ë™êµ¬', 'ì¸ì²œ ë‚¨êµ¬', 'ì¸ì²œ ì—°ìˆ˜êµ¬', 'ì¸ì²œ ë‚¨ë™êµ¬',
            'ì¸ì²œ ë¶€í‰êµ¬', 'ì¸ì²œ ê³„ì–‘êµ¬', 'ì¸ì²œ ì„œêµ¬', 'ì¸ì²œ ê°•í™”êµ°', 'ì¸ì²œ ì˜¹ì§„êµ°',
        ]

        # ê²€ìƒ‰ í‚¤ì›Œë“œ
        self.keywords = [
            'íœ´ëŒ€í°ë§¤ì¥', 'íœ´ëŒ€í°ì„±ì§€', 'ìŠ¤ë§ˆíŠ¸í°ë§¤ì¥', 'í°ë§¤ì¥',
            'íœ´ëŒ€í°ê°€ê²Œ', 'í•¸ë“œí°ê°€ê²Œ', 'ë™ë„¤íœ´ëŒ€í°ë§¤ì¥',
            'íœ´ëŒ€í°íŒë§¤', 'íœ´ëŒ€í°ëŒ€ë¦¬ì ', 'í•¸ë“œí°ë§¤ì¥', 'í•¸ë“œí°íŒë§¤',
            'ìŠ¤ë§ˆíŠ¸í°íŒë§¤', 'íœ´ëŒ€í°ê°œí†µ', 'ê¸°ê¸°ë³€ê²½', 'ë²ˆí˜¸ì´ë™',
            'ì•„ì´í°', 'ê°¤ëŸ­ì‹œ', 'ì•„ì´í°ë§¤ì¥', 'ê°¤ëŸ­ì‹œë§¤ì¥',
            'ì•„ì´í°íŒë§¤', 'ê°¤ëŸ­ì‹œíŒë§¤',
            'íœ´ëŒ€í°ë§¤ì¥ì¶”ì²œ', 'ë¯¿ì„ë§Œí•œíœ´ëŒ€í°ë§¤ì¥', 'ì•ˆì „í•œê°œí†µ',
            'íœ´ëŒ€í°ì„±ì§€í›„ê¸°', 'íœ´ëŒ€í°ë§¤ì¥í›„ê¸°',
        ]

        self.collected_stores = set()

    def init_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”"""
        try:
            self.driver = webdriver.Chrome(options=self.chrome_options)
            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                '''
            })
            print("âœ… Chrome ë¸Œë¼ìš°ì € ì‹œì‘ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False

    def close_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            try:
                self.driver.quit()
                self.driver = None
            except:
                pass

    def extract_010_phones(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ 010 ì „í™”ë²ˆí˜¸ë§Œ ì¶”ì¶œ"""
        if not text:
            return []

        pattern = r'010[-\s]?\d{3,4}[-\s]?\d{4}'
        phones = re.findall(pattern, text)

        normalized = []
        for phone in phones:
            digits = re.sub(r'[-\s]', '', phone)
            if len(digits) == 11:
                formatted = f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
                normalized.append(formatted)
            elif len(digits) == 10:
                formatted = f"{digits[:3]}-{digits[3:6]}-{digits[6:]}"
                normalized.append(formatted)

        return list(set(normalized))

    def search_kakao_map(self, region, keyword):
        """ì¹´ì¹´ì˜¤ë§µì—ì„œ ê²€ìƒ‰"""
        query = f"{region} {keyword}"
        search_url = f"https://map.kakao.com/?q={query}"

        try:
            self.driver.get(search_url)
            time.sleep(random.uniform(3, 5))

            stores = []

            # ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ ê²°ê³¼ ì°¾ê¸°
            try:
                # ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
                items = self.driver.find_elements(By.CSS_SELECTOR, "#info\\.search\\.place\\.list > li")

                print(f"    ğŸ“Œ {len(items)}ê°œ ê²€ìƒ‰ ê²°ê³¼ ë°œê²¬")

                for item in items[:20]:  # ìƒìœ„ 20ê°œë§Œ
                    try:
                        # ë§¤ì¥ëª…
                        name_elem = item.find_element(By.CSS_SELECTOR, ".head_item .tit_name")
                        store_name = name_elem.text.strip()

                        # ë§í¬
                        link_elem = item.find_element(By.CSS_SELECTOR, ".head_item .tit_name")
                        link = link_elem.get_attribute('href')

                        stores.append({
                            'name': store_name,
                            'link': link,
                            'region': region
                        })

                    except Exception as e:
                        continue

            except Exception as e:
                print(f"    âš ï¸  ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")

            return stores

        except Exception as e:
            print(f"    âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    def get_store_detail(self, store):
        """ë§¤ì¥ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            self.driver.get(store['link'])
            time.sleep(random.uniform(2, 3))

            page_text = self.driver.find_element(By.TAG_NAME, 'body').text
            phones = self.extract_010_phones(page_text)

            if phones:
                return {
                    'region': store['region'],
                    'name': store['name'],
                    'phones': phones,
                    'link': store['link']
                }

            return None

        except Exception as e:
            return None

    def save_intermediate_results(self, results, search_count):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        if not results:
            return

        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = self.output_path / f'kakao_stores_intermediate_{search_count}searches_{timestamp}.csv'

            df = pd.DataFrame(results)
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"    ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {len(results)}ê°œ ë§¤ì¥ â†’ {filename.name}")
        except Exception as e:
            print(f"    âš ï¸  ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    def crawl(self, max_searches=2000, save_interval=50):
        """ì¹´ì¹´ì˜¤ë§µ í¬ë¡¤ë§ ì‹¤í–‰"""
        print("=" * 80)
        print("ğŸ—ºï¸  ì¹´ì¹´ì˜¤ë§µ íœ´ëŒ€í° ë§¤ì¥ í¬ë¡¤ëŸ¬")
        print("=" * 80)
        print(f"ğŸ“ ì´ ì§€ì—­ ìˆ˜: {len(self.regions)}ê°œ")
        print(f"ğŸ”‘ ì´ í‚¤ì›Œë“œ ìˆ˜: {len(self.keywords)}ê°œ")
        print("=" * 80)

        all_results = []
        search_count = 0
        max_retries = 3
        retry_count = 0

        for region in self.regions:
            for keyword in self.keywords:
                search_count += 1

                if search_count > max_searches:
                    break

                print(f"\n[{search_count}/{max_searches}] ğŸ” {region} {keyword}")

                while retry_count < max_retries:
                    try:
                        if self.driver is None:
                            print("    ğŸ”„ ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™” ì¤‘...")
                            if not self.init_driver():
                                retry_count += 1
                                time.sleep(5)
                                continue
                            retry_count = 0

                        stores = self.search_kakao_map(region, keyword)

                        for store in stores:
                            detail = self.get_store_detail(store)
                            if detail:
                                for phone in detail['phones']:
                                    store_key = f"{detail['name']}_{phone}"
                                    if store_key not in self.collected_stores:
                                        self.collected_stores.add(store_key)
                                        all_results.append({
                                            'ì§€ì—­ëª…': detail['region'],
                                            'ë§¤ì¥ëª…': detail['name'],
                                            'ì „í™”ë²ˆí˜¸': phone,
                                            'ë§í¬': detail['link']
                                        })
                                        print(f"      ğŸ’¾ ì €ì¥: {detail['name']} ({phone})")

                            time.sleep(random.uniform(1, 2))

                        if search_count % save_interval == 0:
                            print(f"\nğŸ“¦ ì¤‘ê°„ ì €ì¥ ì‹œì  ({search_count}ë²ˆ ê²€ìƒ‰ ì™„ë£Œ)")
                            self.save_intermediate_results(all_results, search_count)

                        wait_time = random.uniform(3, 5)
                        print(f"    â³ {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                        time.sleep(wait_time)

                        break

                    except Exception as e:
                        print(f"    âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        self.close_driver()
                        self.driver = None
                        retry_count += 1
                        if retry_count >= max_retries:
                            print(f"    âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                            break
                        time.sleep(5)

                retry_count = 0

            if search_count > max_searches:
                break

        print("\n" + "=" * 80)
        print("âœ… ìµœì¢… í¬ë¡¤ë§ ì™„ë£Œ")
        print("=" * 80)
        print(f"ğŸ“Š ì´ ê²€ìƒ‰ íšŸìˆ˜: {search_count}íšŒ")
        print(f"ğŸ’¾ ìˆ˜ì§‘ëœ ë§¤ì¥: {len(all_results)}ê°œ")

        if all_results:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            df = pd.DataFrame(all_results)
            final_filename = self.output_path / f'kakao_stores_{timestamp}.csv'
            df.to_csv(final_filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ìµœì¢… íŒŒì¼ ì €ì¥: {final_filename}")

            self.save_intermediate_results(all_results, search_count)

        self.close_driver()
        return all_results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ—ºï¸  ì¹´ì¹´ì˜¤ë§µ í¬ë¡¤ë§ ì‹œì‘...")

    crawler = KakaoMapCrawler(headless=True)
    results = crawler.crawl(max_searches=2000, save_interval=50)

    print(f"\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(results)}ê°œ ë§¤ì¥ ìˆ˜ì§‘")

if __name__ == "__main__":
    main()
